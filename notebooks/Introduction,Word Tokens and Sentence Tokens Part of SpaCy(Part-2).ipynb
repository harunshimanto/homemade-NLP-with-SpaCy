{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Tutorial With SpaCy \n",
    "  \n",
    "  * NLP a form of AI or Artificial Intelligences (Building system that can  do intelligent things).\n",
    "  * NLP or Natural Language Processing - Building system that can understand everyday language. It is a subset of AI.\n",
    "  * SpaCy by Explosion.ai (Matthew Honnibal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](https://i.imgur.com/v55ZxW8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Terms \n",
    "* Tokenization:  Segmenting text into words,punctuations marks etc.\n",
    "* Part-of-speech : (POS) Tagging Assigning word types to tokens,like verb or noun.\n",
    "* Dependency Parsing: Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.\n",
    "* Lemmatization\t: Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”.\n",
    "* Sentence Boundary Detection (SBD):Finding and segmenting individual sentences.\n",
    "* Named Entity Recognition (NER): Labelling named “real-world” objects, like persons, companies or locations.\n",
    "* Similarity:Comparing words, text spans and documents and how similar they are to each other.\n",
    "* Text Classification:Assigning categories or labels to a whole document, or parts of a document.\n",
    "* Rule-based Matching:Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.\n",
    "* Training:Updating and improving a statistical model’s predictions.\n",
    "* Serialization:Saving objects to files or byte strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hide_input": true
   },
   "source": [
    "![Imgur](https://i.imgur.com/q4EfY8Z.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading A Document or Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx = nlp(\"SpaCy is cool tool for nlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpaCy is cool tool for nlp"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx2=nlp(u\"SpaCy is an amazing tool like nltk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpaCy is an amazing tool like nltk"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Tokens \n",
    "* Tokenization == Splitting or segmenting the text into sentences or tokens \n",
    "* .sent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Tokens  \n",
    "* Splitting or segmenting the text into words \n",
    "* .text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpaCy is an amazing tool like nltk"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy\n",
      "is\n",
      "an\n",
      "amazing\n",
      "tool\n",
      "like\n",
      "nltk\n"
     ]
    }
   ],
   "source": [
    "#Word tokens\n",
    "for token in docx2:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpaCy', 'is', 'an', 'amazing', 'tool', 'like', 'nltk']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in docx2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### similar to splitting on spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SpaCy', 'is', 'an', 'amazing', 'tool', 'like', 'nltk']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx2.text.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More about words \n",
    "\n",
    "* .shape_ ==> for shape of word eg. capital,lowercase etc.\n",
    "* .is_alpha ==> returns boolean(true or false) if word is alphabet.\n",
    "* .is_stop ==> returns boolean(true or false) if word is a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpaCy is an amazing tool like nltk"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy XxxXx\n",
      "is xx\n",
      "an xx\n",
      "amazing xxxx\n",
      "tool xxxx\n",
      "like xxxx\n",
      "nltk xxxx\n"
     ]
    }
   ],
   "source": [
    "for word in docx2:\n",
    "    print(word.text,word.shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_doc=nlp(\"Hello hello HELLO HeLLo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token => Hello   Shape: Xxxxx   Alpha => True   Stop Word => False\n",
      "Token => hello   Shape: xxxx   Alpha => True   Stop Word => False\n",
      "Token => HELLO   Shape: XXXX   Alpha => True   Stop Word => False\n",
      "Token => HeLLo   Shape: XxXXx   Alpha => True   Stop Word => False\n"
     ]
    }
   ],
   "source": [
    "for word in ex_doc:\n",
    "    print(\"Token =>\",word.text,\"  Shape:\",word.shape_,\"  Alpha =>\",word.is_alpha,\"  Stop Word =>\",word.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Of Speech Tagging\n",
    "\n",
    "* NB attribute_ ==> Returns readable string representation of attribute.\n",
    "* .pos \n",
    "* .pos_ ==> exposes Google Universal pos_tag,simple \n",
    "* .tag \n",
    "* .tag_ ==> exposes Treebank,detailed,for training your own model \n",
    "* * Uses\n",
    "* * Sentiment analysis, Homonym Disambuguity, Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"He drinks a drink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word :  He ,   Part of Speech :  PRON\n",
      "Word :  drinks ,   Part of Speech :  VERB\n",
      "Word :  a ,   Part of Speech :  DET\n",
      "Word :  drink ,   Part of Speech :  NOUN\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(\"Word : \" , word.text, \",\" \"   Part of Speech : \", word.pos_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=nlp(\"I fish a fish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word :  I ,   Part of Speech :  PRON    Tag :  PRP\n",
      "Word :  fish ,   Part of Speech :  VERB    Tag :  VBP\n",
      "Word :  a ,   Part of Speech :  DET    Tag :  DT\n",
      "Word :  fish ,   Part of Speech :  NOUN    Tag :  NN\n"
     ]
    }
   ],
   "source": [
    "for word in doc1:\n",
    "    print(\"Word : \" , word.text, \",\" \"   Part of Speech : \", word.pos_ , \"  \", \"Tag : \", word.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to know meaning of the pos abbreviation \n",
    "\n",
    "* spacy.explain('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, singular or mass'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1=nlp(u\"All the faith he had had had no effect on the outcome of his life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Word : ', 'All', 'Tag : ', 'PDT', 'Part of Speech : ', 'DET')\n",
      "('Word : ', 'the', 'Tag : ', 'DT', 'Part of Speech : ', 'DET')\n",
      "('Word : ', 'faith', 'Tag : ', 'NN', 'Part of Speech : ', 'NOUN')\n",
      "('Word : ', 'he', 'Tag : ', 'PRP', 'Part of Speech : ', 'PRON')\n",
      "('Word : ', 'had', 'Tag : ', 'VBD', 'Part of Speech : ', 'VERB')\n",
      "('Word : ', 'had', 'Tag : ', 'VBN', 'Part of Speech : ', 'VERB')\n",
      "('Word : ', 'had', 'Tag : ', 'VBN', 'Part of Speech : ', 'VERB')\n",
      "('Word : ', 'no', 'Tag : ', 'DT', 'Part of Speech : ', 'DET')\n",
      "('Word : ', 'effect', 'Tag : ', 'NN', 'Part of Speech : ', 'NOUN')\n",
      "('Word : ', 'on', 'Tag : ', 'IN', 'Part of Speech : ', 'ADP')\n",
      "('Word : ', 'the', 'Tag : ', 'DT', 'Part of Speech : ', 'DET')\n",
      "('Word : ', 'outcome', 'Tag : ', 'NN', 'Part of Speech : ', 'NOUN')\n",
      "('Word : ', 'of', 'Tag : ', 'IN', 'Part of Speech : ', 'ADP')\n",
      "('Word : ', 'his', 'Tag : ', 'PRP$', 'Part of Speech : ', 'DET')\n",
      "('Word : ', 'life', 'Tag : ', 'NN', 'Part of Speech : ', 'NOUN')\n"
     ]
    }
   ],
   "source": [
    "for word in ex1:\n",
    "    print((\"Word : \" , word.text , \"Tag : \", word.tag_ , \"Part of Speech : \",word.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic Dependency \n",
    "\n",
    "* It helps us to know the relation between tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3 = nlp(\"Sally likes Sam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Word : ', 'Sally', 'Tag : ', 'NNP', 'Part of Speech : ', 'PROPN', ' Dependency :', 'nsubj')\n",
      "('Word : ', 'likes', 'Tag : ', 'VBZ', 'Part of Speech : ', 'VERB', ' Dependency :', 'ROOT')\n",
      "('Word : ', 'Sam', 'Tag : ', 'NNP', 'Part of Speech : ', 'PROPN', ' Dependency :', 'dobj')\n"
     ]
    }
   ],
   "source": [
    "for word in ex3:\n",
    "    print((\"Word : \" , word.text , \"Tag : \", word.tag_ , \"Part of Speech : \",word.pos_, \" Dependency :\",word.dep_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Dependency using displaCy\n",
    "\n",
    "* from spacy import displacy\n",
    "* displacy.serve()\n",
    "* displacy.render(jupyter=True) # for jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9c60516feda148b9a132f89334a9dae0-0\" class=\"displacy\" width=\"575\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Sally</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">likes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Sam</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c60516feda148b9a132f89334a9dae0-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c60516feda148b9a132f89334a9dae0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c60516feda148b9a132f89334a9dae0-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c60516feda148b9a132f89334a9dae0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(ex3,style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Thanks for reading this notebook.Keep In Touch With Us.Like Our Page [Quantum.ai](https://www.facebook.com/Quantumaibd)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
